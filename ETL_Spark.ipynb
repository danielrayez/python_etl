{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "el objetivo es hacer una etl con spark a un conjunto de datos de un archivo excel que también fue sometido a una transformación con pandas"
      ],
      "metadata": {
        "id": "MTANPqfxN7xj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AyQc7prdH-RP"
      },
      "outputs": [],
      "source": [
        "                #COMIENZO ETL CON SPARK\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "from google.colab.output import serve_kernel_port_as_window\n",
        "import pandas as pd\n",
        "from pyspark.sql.functions import expr, to_date, split, explode, posexplode, concat_ws, broadcast, lower\n",
        "import time\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Mostrar Spark UI como iframe\n",
        "# serve_kernel_port_as_window(4050, path=\"/jobs/index.html\")\n",
        "\n",
        "# # Iniciar Spark con UI en el puerto 4050\n",
        "# spark = SparkSession.builder \\\n",
        "#     .appName(\"MiAppColab\") \\\n",
        "#     .config(\"spark.ui.port\", \"4050\") \\\n",
        "#     .getOrCreate()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "mlzx2A3pOtRk",
        "outputId": "210b854c-4780-44b6-80e9-3e372a9989ff",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mWarning: This function may stop working due to changes in browser security.\n",
            "Try `serve_kernel_port_as_iframe` instead. \u001b[0m\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "(async (port, path, text, element) => {\n",
              "    if (!google.colab.kernel.accessAllowed) {\n",
              "      return;\n",
              "    }\n",
              "    element.appendChild(document.createTextNode(''));\n",
              "    const url = await google.colab.kernel.proxyPort(port);\n",
              "    const anchor = document.createElement('a');\n",
              "    anchor.href = new URL(path, url).toString();\n",
              "    anchor.target = '_blank';\n",
              "    anchor.setAttribute('data-href', url + path);\n",
              "    anchor.textContent = text;\n",
              "    element.appendChild(anchor);\n",
              "  })(4050, \"/jobs/index.html\", \"https://localhost:4050/jobs/index.html\", window.element)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0qtXjCHaLRmV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inicio = time.time()"
      ],
      "metadata": {
        "id": "w9NB83Rc2x9L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#leer archivo .xlsx\n",
        "\n",
        "df_pandas = pd.read_excel('/content/Datos.xlsx', sheet_name=\"Hoja2 RF04\", skiprows=4)\n"
      ],
      "metadata": {
        "id": "Vm1Eo7YSXapK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Auxiliares\n",
        "\n",
        "meses = {\"ene\": \"01\", \"feb\": \"02\", \"mar\": \"03\", \"abr\": \"04\", \"may\": \"05\", \"jun\": \"06\",\n",
        "         \"jul\": \"07\", \"ago\": \"08\", \"sep\": \"09\", \"oct\": \"10\", \"nov\": \"11\", \"dic\": \"12\"}\n",
        "\n",
        "cols_base = ['CANAL', 'GRUPO', 'CODIGO']\n",
        "\n",
        "cajas = [\n",
        "    'abr-25', 'may-25', 'jun-25', 'jul-25', 'ago-25', 'sep-25',\n",
        "    'oct-25', 'nov-25', 'dic-25', 'ene-26', 'feb-26', 'mar-26'\n",
        "]\n",
        "\n",
        "precios = [\n",
        "    'abr_25-Pr Netos', 'may_25-Pr Netos', 'jun_25-Pr Netos', 'jul_25-Pr Netos',\n",
        "    'ago_25-Pr Netos', 'sep_25-Pr Netos', 'oct_25-Pr Netos', 'nov_25-Pr Netos',\n",
        "    'dic_25-Pr Netos', 'ene_26-Pr Netos', 'feb_26-Pr Netos', 'mar_26-Pr Netos'\n",
        "]\n",
        "\n",
        "fap = [\n",
        "    'Abr_25 FAP', 'May_25 FAP', 'Jun_25 FAP', 'Jul_25 FAP',\n",
        "    'Ago_25 FAP', 'Sep_25 FAP', 'Oct_25 FAP', 'Nov_25 FAP',\n",
        "    'Dic_25 FAP', 'Ene_26 FAP', 'Feb_26 FAP', 'Mar_26 FAP'\n",
        "]\n",
        "\n",
        "ptp = [\n",
        "    'Abr_25 PTP $$', 'May_25 PTP $$', 'Jun_25 PTP $$', 'Jul_25 PTP $$',\n",
        "    'Ago_25 PTP $$', 'Sep_25 PTP $$', 'Oct_25 PTP $$', 'Nov_25 PTP $$',\n",
        "    'Dic_25 PTP $$', 'Ene_26 PTP $$', 'Feb_26 PTP $$', 'Mar_26 PTP $$'\n",
        "]\n",
        "\n",
        "# Selección total\n",
        "columnas_seleccionadas = cols_base + cajas + precios + fap + ptp\n",
        "df = df_pandas[columnas_seleccionadas]"
      ],
      "metadata": {
        "id": "ls9ZvulnTSdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_spark = spark.createDataFrame(df).cache()\n",
        "\n"
      ],
      "metadata": {
        "id": "8edZbAEhJrZt",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Funcion para despivotar columnas y generar df distintos\n",
        "\n",
        "def unpivot(df, id_cols, value_cols, var_name=\"Fecha\", val_name=\"Valor\"):\n",
        "\n",
        "    stack_expr = f\"stack({len(value_cols)}, \" + \\\n",
        "                 \", \".join([f\"'{col}', `{col}`\" for col in value_cols]) + \\\n",
        "                 f\") as ({var_name}, {val_name})\"\n",
        "\n",
        "    return df.select(*id_cols, expr(stack_expr))"
      ],
      "metadata": {
        "id": "ptKhqAfxROLC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_cajas = unpivot(df_spark, id_cols=cols_base, value_cols=cajas)\n",
        "df_fap = unpivot(df_spark, id_cols=cols_base, value_cols= fap)\n",
        "df_ptp = unpivot(df_spark, id_cols=cols_base, value_cols=ptp)\n",
        "df_precios = unpivot(df_spark, id_cols=cols_base, value_cols=precios)\n",
        "df_spark.unpersist()"
      ],
      "metadata": {
        "id": "RxOZAHIYZs7O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9bb0c8d8-511e-4f8d-9951-0a616c7fb325"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[CANAL: string, GRUPO: string, CODIGO: bigint, abr-25: double, may-25: double, jun-25: double, jul-25: double, ago-25: double, sep-25: double, oct-25: double, nov-25: double, dic-25: double, ene-26: double, feb-26: double, mar-26: double, abr_25-Pr Netos: double, may_25-Pr Netos: double, jun_25-Pr Netos: double, jul_25-Pr Netos: double, ago_25-Pr Netos: double, sep_25-Pr Netos: double, oct_25-Pr Netos: double, nov_25-Pr Netos: double, dic_25-Pr Netos: double, ene_26-Pr Netos: double, feb_26-Pr Netos: double, mar_26-Pr Netos: double, Abr_25 FAP: double, May_25 FAP: double, Jun_25 FAP: double, Jul_25 FAP: double, Ago_25 FAP: double, Sep_25 FAP: double, Oct_25 FAP: double, Nov_25 FAP: double, Dic_25 FAP: double, Ene_26 FAP: double, Feb_26 FAP: double, Mar_26 FAP: double, Abr_25 PTP $$: double, May_25 PTP $$: double, Jun_25 PTP $$: double, Jul_25 PTP $$: double, Ago_25 PTP $$: double, Sep_25 PTP $$: double, Oct_25 PTP $$: double, Nov_25 PTP $$: double, Dic_25 PTP $$: double, Ene_26 PTP $$: double, Feb_26 PTP $$: double, Mar_26 PTP $$: double]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#limpiar columna Fecha en df_cajas y cambiar a tipo date\n",
        "\n",
        "df_cajas = df_cajas.withColumn(\n",
        "    \"Fecha\", expr(\"substring(Fecha, 1, 6)\")\n",
        "    ).withColumn(\"mes\", lower( (split(\"Fecha\", \"-\").getItem(0)))\n",
        "    ).withColumn(\"año\", (split(\"Fecha\", \"-\").getItem(1))\n",
        "    ).replace(to_replace=meses, subset=[\"mes\"]\n",
        "    ).withColumn(\"Fecha\",to_date(concat_ws(\"-\", \"mes\", \"año\"),  \"MM-yy\")\n",
        "    ).withColumnRenamed(\"Valor\", \"cajas\").drop(\"mes\", \"año\")\n"
      ],
      "metadata": {
        "id": "tAaMJQ_xesGi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def limpieza(df , nombre = \"Valor\"): #esta funcion es para fap, precios y ptp pues tienen misma estructura\n",
        "\n",
        "  df = df.withColumn(\n",
        "    \"Fecha\", expr(\"substring(Fecha, 1, 6)\")\n",
        "    ).withColumn(\"mes\", lower((split(\"Fecha\", \"_\").getItem(0)))\n",
        "    ).withColumn(\"año\", (split(\"Fecha\", \"_\").getItem(1))\n",
        "    ).replace(to_replace=meses, subset=[\"mes\"]\n",
        "    ).withColumn (\"Fecha\", to_date(concat_ws(\"-\", \"mes\", \"año\"),  \"MM-yy\")\n",
        "    ).drop(\"mes\", \"año\").withColumnRenamed(\"Valor\", nombre)\n",
        "  return df"
      ],
      "metadata": {
        "id": "QUpSbvDcUmER"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_fap = limpieza(df_fap, \"fap\")\n",
        "df_ptp = limpieza(df_ptp, \"ptp\")\n",
        "df_precios = limpieza(df_precios, \"precios\")\n"
      ],
      "metadata": {
        "id": "thj6hA1WUlUR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# join desde cajas a cada uno de los df\n",
        "df_fin = df_cajas.join(broadcast(df_fap), on=[\"CANAL\", \"GRUPO\", \"CODIGO\", \"Fecha\"], how=\"left\"\n",
        "  ).join(broadcast(df_ptp), on=[\"CANAL\", \"GRUPO\", \"CODIGO\", \"Fecha\"], how=\"left\"\n",
        "  ).join(broadcast(df_precios), on=[\"CANAL\", \"GRUPO\", \"CODIGO\", \"Fecha\"], how=\"left\"\n",
        "  )\n"
      ],
      "metadata": {
        "id": "29F4tA8KVams"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_fin = df_fin.withColumn(\"fact_operativa\", (df_fin.cajas * df_fin.precios)/1000 )\n",
        "df_fin.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kv_ITrSaYu5z",
        "outputId": "f1480a70-f1a0-4fb6-9188-7f57c41d7987"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-------+-------+----------+-------+---+---------+-------+--------------+\n",
            "|CANAL|  GRUPO| CODIGO|     Fecha|  cajas|fap|      ptp|precios|fact_operativa|\n",
            "+-----+-------+-------+----------+-------+---+---------+-------+--------------+\n",
            "| GGCC|WALMART|1060553|2025-04-01| 2500.0|0.0|  19615.7|30178.0|       75445.0|\n",
            "| GGCC|WALMART|1060553|2025-05-01| 4500.0|0.0|      0.0|30178.0|      135801.0|\n",
            "| GGCC|WALMART|1060553|2025-06-01| 4500.0|0.0|      0.0|30178.0|      135801.0|\n",
            "| GGCC|WALMART|1060553|2025-07-01|15000.0|0.0| 117694.2|30178.0|      452670.0|\n",
            "| GGCC|WALMART|1060553|2025-08-01|18000.0|0.0|141233.04|30178.0|      543204.0|\n",
            "+-----+-------+-------+----------+-------+---+---------+-------+--------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fin = time.time()\n",
        "print(f\"tiempo de lectura: {fin-inicio:.2f} segundos \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lRIhVdC126zt",
        "outputId": "7ce12405-965c-4e83-d370-77a487331131"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tiempo de lectura: 93.26 segundos \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sX8JeyD9Ntxl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "ckSGlPeF7O04"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}